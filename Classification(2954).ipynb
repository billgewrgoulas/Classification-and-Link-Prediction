{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b98333cf-4f85-4ec8-b2b1-1c45f6a6a6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn.linear_model as linear_model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import json\n",
    "import gensim\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5b6353-b38f-42b8-ac2d-a369681f01fd",
   "metadata": {},
   "source": [
    "# Step 0 - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65ae62fa-16f9-4ce9-95b7-e03d03184727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Chill dive bar that was around the corner from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Definitely a worthy place to stay.   The room ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Once upon Stella was a great restaurant. It wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The spicy calamari is not to be missed! As are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>It provided great peace of mind to know that w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                               text\n",
       "0      0  Chill dive bar that was around the corner from...\n",
       "1      1  Definitely a worthy place to stay.   The room ...\n",
       "2      0  Once upon Stella was a great restaurant. It wa...\n",
       "3      1  The spicy calamari is not to be missed! As are...\n",
       "4      1  It provided great peace of mind to know that w..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "reviews = {\"stars\":[], \"text\":[]}\n",
    "ids = set()\n",
    "\n",
    "# ################## get businesses located in Boston####################\n",
    "b = open('business.json', 'r', encoding='utf-8')\n",
    "el = b.readline().rstrip('\\n')\n",
    "while el:\n",
    "    e = json.loads(el)\n",
    "    if e[\"city\"] == \"Boston\":\n",
    "        ids.add(e[\"business_id\"])\n",
    "    el = b.readline().rstrip('\\n')\n",
    "b.close()\n",
    "#############################################################\n",
    "\n",
    "#############get the reviews of the businesses in Boston in 2020#####\n",
    "r = open('reviews.json', 'r', encoding='utf-8')\n",
    "el = r.readline().rstrip('\\n')\n",
    "while el:\n",
    "    e = json.loads(el)\n",
    "    if e[\"business_id\"] in ids and e[\"date\"].split('-')[0] == '2020':\n",
    "        reviews[\"stars\"].append(1 if e[\"stars\"] > 3 else 0)\n",
    "        reviews[\"text\"].append(e[\"text\"])\n",
    "    el = r.readline().rstrip('\\n')\n",
    "r.close()\n",
    "################################################################\n",
    "\n",
    "reviews_df = pd.DataFrame(reviews)\n",
    "display(reviews_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e591fb1b-6d91-487f-a392-e68de258e398",
   "metadata": {},
   "source": [
    "# Apply KFold and initialize the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a57a1f3-f92c-49f4-9350-efc4c752594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfidf = TfidfVectorizer(analyzer = 'word', stop_words = 'english', max_features=300)\n",
    "\n",
    "lr_clf = linear_model.LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "svm_clf = svm.SVC()\n",
    "knn = KNeighborsClassifier(n_neighbors=100)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=2021)\n",
    "folds = kf.split(reviews_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28c1f71-87b7-4bc9-8299-a09eb14985bb",
   "metadata": {},
   "source": [
    " # Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e67999-f100-4ab9-bdfe-b94ebbf53ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#################classifiers################\n",
    "\n",
    "def LR(X_train, y_train, X_test):\n",
    "    lr_clf.fit(X_train, y_train)\n",
    "    return lr_clf.predict(X_test)\n",
    "\n",
    "def SVM(X_train, y_train, X_test):\n",
    "    svm_clf.fit(X_train, y_train)\n",
    "    return svm_clf.predict(X_test)\n",
    "\n",
    "def K_NN(X_train, y_train, X_test):\n",
    "    knn.fit(X_train, y_train)\n",
    "    return knn.predict(X_test)\n",
    "\n",
    "#################metrics####################\n",
    "\n",
    "def get_confusion_matrix(real_classes, predicted_classes):\n",
    "    return confusion_matrix(real_classes, predicted_classes)\n",
    "\n",
    "def get_metrics(m):\n",
    "    \n",
    "    #total accuracy\n",
    "    a = (m[0][0] + m[1][1])/(m[0][0] + m[1][0] + m[0][1] + m[1][1])\n",
    "    \n",
    "    #class 0 precision + recall + f1\n",
    "    p0 = m[0][0]/(m[0][0] + m[1][0])\n",
    "    r0 = m[0][0]/(m[0][0] + m[0][1])\n",
    "    f10 = 2*(p0 * r0)/(p0 + r0)\n",
    "    \n",
    "    #class 1 precision + recall + f1\n",
    "    p1 = m[1][1]/(m[1][1] + m[0][1])\n",
    "    r1 = m[1][1]/(m[1][1] + m[1][0])\n",
    "    f11 = 2*(p1 * r1)/(p1 + r1)\n",
    "    return ([p0, p1, r0, r1, f10, f11], a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15501528-2826-478a-872e-4c83a2e787ef",
   "metadata": {},
   "source": [
    "# Step 1a, 5-fold cross validation using TfIdf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f660f8d2-c843-4586-b8d3-be3cff50aadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrices: \n",
      "SVM: \n",
      "[[ 5319  4750]\n",
      " [ 3872 18075]]\n",
      "-------------------------------------------------------\n",
      "LR: \n",
      "[[ 5288  4781]\n",
      " [ 3844 18103]]\n",
      "-------------------------------------------------------\n",
      "KNN: \n",
      "[[ 3029  7040]\n",
      " [ 1919 20028]]\n",
      "-------------------------------------------------------\n",
      "Metrics per classifier: \n",
      "-------------------------------------------------------\n",
      "Mean Precision, Recall, F1 scores per class for each Classifier:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision1</th>\n",
       "      <th>Precision2</th>\n",
       "      <th>Recall1</th>\n",
       "      <th>Recall2</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.578718</td>\n",
       "      <td>0.791895</td>\n",
       "      <td>0.528255</td>\n",
       "      <td>0.823575</td>\n",
       "      <td>0.552336</td>\n",
       "      <td>0.807424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.579063</td>\n",
       "      <td>0.791077</td>\n",
       "      <td>0.525176</td>\n",
       "      <td>0.824851</td>\n",
       "      <td>0.550805</td>\n",
       "      <td>0.807611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.612167</td>\n",
       "      <td>0.739914</td>\n",
       "      <td>0.300824</td>\n",
       "      <td>0.912562</td>\n",
       "      <td>0.403409</td>\n",
       "      <td>0.817219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Precision1  Precision2   Recall1   Recall2       F11       F12\n",
       "SVM    0.578718    0.791895  0.528255  0.823575  0.552336  0.807424\n",
       "LR     0.579063    0.791077  0.525176  0.824851  0.550805  0.807611\n",
       "KNN    0.612167    0.739914  0.300824  0.912562  0.403409  0.817219"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracies of each Classifier across all 5 folds\n",
      "-------------------------------------------------------\n",
      "LR:  0.7306034482758621\n",
      "SVM:  0.7306971514242878\n",
      "KNN:  0.720171164417791\n",
      "-------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "real_classes = np.array([])\n",
    "predicted_lr = np.array([])\n",
    "predicted_svm = np.array([])\n",
    "predicted_knn = np.array([])\n",
    "\n",
    "for train, test in folds:\n",
    "    \n",
    "    train_data = reviews_df.iloc[train]\n",
    "    test_data = reviews_df.iloc[test]\n",
    "    \n",
    "    X_train, X_test = tfidf.fit_transform(train_data['text']), tfidf.fit_transform(test_data['text'])\n",
    "    y_train, y_test = train_data['stars'], test_data[\"stars\"]\n",
    "    \n",
    "    lr_pred = LR(X_train, y_train, X_test)\n",
    "    svm_pred = SVM(X_train, y_train, X_test)\n",
    "    knn_pred = K_NN(X_train, y_train, X_test)\n",
    "    \n",
    "    real_classes = np.append(real_classes, y_test)\n",
    "    predicted_lr = np.append(predicted_lr, lr_pred)\n",
    "    predicted_svm = np.append(predicted_svm, svm_pred)\n",
    "    predicted_knn = np.append(predicted_knn, knn_pred)\n",
    "\n",
    "#calculate the confusion matrices\n",
    "m1 = get_confusion_matrix(real_classes, predicted_svm)\n",
    "m2 = get_confusion_matrix(real_classes, predicted_lr)\n",
    "m3 = get_confusion_matrix(real_classes, predicted_knn)\n",
    "\n",
    "#get the metrics of the classifiers\n",
    "metrics_svm = get_metrics(m1)\n",
    "metrics_lr = get_metrics(m2)\n",
    "metrics_knn = get_metrics(m3)\n",
    "\n",
    "print('confusion matrices: ')\n",
    "print('SVM: ')\n",
    "print(m1)\n",
    "print('-------------------------------------------------------')\n",
    "\n",
    "print('LR: ')\n",
    "print(m2)\n",
    "print('-------------------------------------------------------')\n",
    "\n",
    "print('KNN: ')\n",
    "print(m3)\n",
    "print('-------------------------------------------------------')\n",
    "\n",
    "print('Metrics per classifier: ')\n",
    "print('-------------------------------------------------------')\n",
    "\n",
    "print('Mean Precision, Recall, F1 scores per class for each Classifier:')\n",
    "stats = [metrics_svm[0], metrics_lr[0], metrics_knn[0]]\n",
    "df = pd.DataFrame(stats, index=['SVM', 'LR', 'KNN'], columns = ['Precision1', 'Precision2', 'Recall1', 'Recall2', 'F11', 'F12'])\n",
    "\n",
    "print('Mean Accuracies of each Classifier across all 5 folds')\n",
    "print('-------------------------------------------------------')\n",
    "print('LR: ', metrics_lr[1])\n",
    "print('SVM: ', metrics_svm[1])\n",
    "print('KNN: ', metrics_knn[1])\n",
    "print('-------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd432ee3-4c18-4181-8514-7cb82633fc24",
   "metadata": {},
   "source": [
    "## Notes\n",
    "The metrics were calculated using exclusively the mean Confusion Matrix across all 5 folds for each classifier. We calculate the actual classes as well as the predictions for each fold and then combine them with the rest, to finally get the total mean confusion matrix. The metrics are calculated based on the true positives / negatives as well as the false positives / negatives for each class. Based on the metrics we observe that the 3 classifiers have similar accuracy. In addition to tfidf and the CNN classifier, some experiments were performed to find good numbers from features / neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b4319f-681e-4fb6-9edd-07895f8aded8",
   "metadata": {},
   "source": [
    "# Step 1b Words with biggest/smallest coefficients in the last fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f604d9da-a87b-4428-a82c-4514a52439ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 most important words from best to worst: \n",
      "('amazing', 'delicious', 'perfect', 'great', 'best', 'highly', 'definitely', 'excellent', 'thank', 'wonderful', 'fantastic', 'love', 'favorite', 'perfectly', 'happy', 'awesome', 'professional', 'loved', 'enjoyed', 'friendly')\n",
      "------------------------------------------------\n",
      "20 least important words from worst to best: \n",
      "('rude', 'money', 'ok', 'told', 'disappointed', 'asked', 'bad', 'wasn', 'don', 'wouldn', 'tasted', 'left', 'pay', 'manager', 'cold', 'didn', 'flavor', '15', 'just', 'better')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for train, test in folds:\n",
    "    pass\n",
    "\n",
    "train_data = reviews_df.iloc[train]\n",
    "test_data = reviews_df.iloc[test]\n",
    "\n",
    "X_train = tfidf.fit_transform(train_data['text'])\n",
    "y_train = train_data['stars']\n",
    "\n",
    "features = tfidf.get_feature_names_out()\n",
    "\n",
    "X_test = tfidf.fit_transform(test_data['text'])\n",
    "y_test = test_data[\"stars\"]\n",
    "    \n",
    "LR(X_train, y_train, X_test)\n",
    "weights = lr_clf.coef_.flatten()\n",
    "\n",
    "l = list(zip(weights, features))\n",
    "l.sort(reverse=True, key=lambda x: x[0])\n",
    "\n",
    "f = list(zip(*l))\n",
    "\n",
    "print('20 most important words from best to worst: ')\n",
    "print(f[1][0:20])\n",
    "print('------------------------------------------------')\n",
    "print('20 least important words from worst to best: ')\n",
    "print(f[1][-20:][::-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8a323d-e183-4dd0-b538-3ff453d32dd3",
   "metadata": {},
   "source": [
    "## Notes\n",
    "We see that the best words used by the classifier which have the heaviest weights have a positive meaning and are able to represent a positive review. On the contrary, the words with the smallest weights are either neutral in meaning or are able to describe a negative review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c684f433-1f95-40c0-8c45-2b6108f7c7b3",
   "metadata": {},
   "source": [
    "# Step 2 cross validation using Google Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d205c54-9ee8-4d74-929d-eb1282c5d476",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrices: \n",
      "SVM: \n",
      "[[ 7781  2288]\n",
      " [ 1334 20613]]\n",
      "-------------------------------------------------------\n",
      "LR: \n",
      "[[ 7542  2527]\n",
      " [ 1386 20561]]\n",
      "-------------------------------------------------------\n",
      "KNN: \n",
      "[[ 6627  3442]\n",
      " [ 2684 19263]]\n",
      "-------------------------------------------------------\n",
      "Metrics per classifier: \n",
      "-------------------------------------------------------\n",
      "Mean Precision, Recall, F1 scores per class for each Classifier:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision1</th>\n",
       "      <th>Precision2</th>\n",
       "      <th>Recall1</th>\n",
       "      <th>Recall2</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.853648</td>\n",
       "      <td>0.900092</td>\n",
       "      <td>0.772768</td>\n",
       "      <td>0.939217</td>\n",
       "      <td>0.811197</td>\n",
       "      <td>0.919238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.844758</td>\n",
       "      <td>0.890549</td>\n",
       "      <td>0.749032</td>\n",
       "      <td>0.936848</td>\n",
       "      <td>0.794020</td>\n",
       "      <td>0.913112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.711739</td>\n",
       "      <td>0.848403</td>\n",
       "      <td>0.658159</td>\n",
       "      <td>0.877705</td>\n",
       "      <td>0.683901</td>\n",
       "      <td>0.862806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Precision1  Precision2   Recall1   Recall2       F11       F12\n",
       "SVM    0.853648    0.900092  0.772768  0.939217  0.811197  0.919238\n",
       "LR     0.844758    0.890549  0.749032  0.936848  0.794020  0.913112\n",
       "KNN    0.711739    0.848403  0.658159  0.877705  0.683901  0.862806"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracies of each Classifier across all 5 folds\n",
      "-------------------------------------------------------\n",
      "LR:  0.877779860069965\n",
      "SVM:  0.8868690654672664\n",
      "KNN:  0.8086581709145427\n",
      "-------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "path = api.load(\"word2vec-google-news-300\", return_path=True)\n",
    "g_model = gensim.models.KeyedVectors.load_word2vec_format(path, binary=True)\n",
    "\n",
    "y = np.array(reviews_df[\"stars\"])\n",
    "reviews = reviews_df[\"text\"].tolist()\n",
    "\n",
    "X = []\n",
    "for review in reviews:\n",
    "    vx = np.zeros(300)\n",
    "    length = 0\n",
    "    for w in review.split(' '): \n",
    "        if w in g_model:\n",
    "            length += 1\n",
    "            vx += g_model[w]\n",
    "    if length != 0: vx /= length\n",
    "    X.append(vx)\n",
    "    \n",
    "X = np.array(X)\n",
    "\n",
    "real_classes = np.array([])\n",
    "predicted_lr = np.array([])\n",
    "predicted_svm = np.array([])\n",
    "predicted_knn = np.array([])\n",
    "\n",
    "for train, test in folds:\n",
    "    \n",
    "    X_train, y_train = X[train], y[train]\n",
    "    X_test, y_test = X[test], y[test]\n",
    "    \n",
    "    lr_pred = LR(X_train, y_train, X_test)\n",
    "    svm_pred = SVM(X_train, y_train, X_test)\n",
    "    knn_pred = K_NN(X_train, y_train, X_test)\n",
    "    \n",
    "    real_classes = np.append(real_classes, y_test)\n",
    "    predicted_lr = np.append(predicted_lr, lr_pred)\n",
    "    predicted_svm = np.append(predicted_svm, svm_pred)\n",
    "    predicted_knn = np.append(predicted_knn, knn_pred)\n",
    "    \n",
    "#calculate the confusion matrices\n",
    "m1 = get_confusion_matrix(real_classes, predicted_svm)\n",
    "m2 = get_confusion_matrix(real_classes, predicted_lr)\n",
    "m3 = get_confusion_matrix(real_classes, predicted_knn)\n",
    "\n",
    "#get the metrics of the classifiers\n",
    "metrics_svm = get_metrics(m1)\n",
    "metrics_lr = get_metrics(m2)\n",
    "metrics_knn = get_metrics(m3)\n",
    "\n",
    "print('confusion matrices: ')\n",
    "\n",
    "print('SVM: ')\n",
    "print(m1)\n",
    "print('-------------------------------------------------------')\n",
    "\n",
    "print('LR: ')\n",
    "print(m2)\n",
    "print('-------------------------------------------------------')\n",
    "\n",
    "print('KNN: ')\n",
    "print(m3)\n",
    "print('-------------------------------------------------------')\n",
    "\n",
    "print('Metrics per classifier: ')\n",
    "print('-------------------------------------------------------')\n",
    "\n",
    "print('Mean Precision, Recall, F1 scores per class for each Classifier:')\n",
    "stats = [metrics_svm[0], metrics_lr[0], metrics_knn[0]]\n",
    "df = pd.DataFrame(stats, index=['SVM', 'LR', 'KNN'], columns = ['Precision1', 'Precision2', 'Recall1', 'Recall2', 'F11', 'F12'])\n",
    "display(df)\n",
    "\n",
    "print('Mean Accuracies of each Classifier across all 5 folds')\n",
    "print('-------------------------------------------------------')\n",
    "print('LR: ', metrics_lr[1])\n",
    "print('SVM: ', metrics_svm[1])\n",
    "print('KNN: ', metrics_knn[1])\n",
    "print('-------------------------------------------------------\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589889e5",
   "metadata": {},
   "source": [
    "## Notes\n",
    "From the metrics we see that google embeddings significantly improve the results compared to the simple tfidf vectorizer, with the SVM algorithm having the best accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
